[
["index.html", "Mealyzer diabetes app study exploratory data visualization Chapter 1 Introduction", " Mealyzer diabetes app study exploratory data visualization Klyment Mamykin, Sunny Lee, Jinrong Cao 2019-12-01 Chapter 1 Introduction "],
["data-sources.html", "Chapter 2 Data sources 2.1 Mealyzer application and functionality 2.2 Dataset description 2.3 Dataset collection artifacts 2.4 Data Import", " Chapter 2 Data sources 2.1 Mealyzer application and functionality 2.2 Dataset description bg readings meals meal details, evaluator nutrients, user nutriends, calculated fields (calculated calories, nutrient proportions) activities sleep meal photos 2.3 Dataset collection artifacts pre and post meal bg times evaluator 2.4 Data Import raw_data_path = &quot;~/Dropbox/MealyzerData&quot; mealyser_data_overview = read_csv(file.path(raw_data_path, &quot;mealyzer_data_overview.csv&quot;), col_types = cols()) 2.4.1 Selecting users for the analysis users = mealyser_data_overview %&gt;% filter(complete_meals &gt; 14) print(users[[&quot;user_id&quot;]]) ## [1] 24 56 57 58 88 1665 1809 1821 1883 1957 1983 2004 2254 2262 ## [15] 2288 2308 2312 2316 2329 2392 2475 2536 2702 2721 2822 2890 2942 2948 read_mealyzer_files &lt;- function(data_dir, user_ids, file_name, add_user_id, col_types) { result &lt;- c() for (user_id in user_ids) { file_path = file.path(data_dir, as.character(user_id), file_name) df = read_csv(file_path, col_types = col_types) if (add_user_id) { df = cbind(user_id = user_id, df) } if (length(result) == 0) { result &lt;- df } else { result &lt;- rbind(result, df) } } return(result) } as.timestamp &lt;- function(minutes_since, anchor_date = &#39;2019-01-01 00:00:00 EST&#39;) { anchor_time = as.POSIXct(anchor_date) return(anchor_time + minutes_since * 60) } as.meals_kind &lt;- function(values) { return(fct_relevel(values, c(&quot;breakfast&quot;, &quot;morning_snack&quot;, &quot;lunch&quot;, &quot;afternoon_snack&quot;, &quot;dinner&quot;, &quot;after_dinner_snack&quot;))) } print_df &lt;- function(df, ...) { print(df %&gt;% select(...)) return(df) } bg_readings = read_mealyzer_files(raw_data_path, users[[&quot;user_id&quot;]], &quot;bg_labeled.csv&quot;, add_user_id = TRUE, col_types = cols( time = col_double(), bg = col_double(), meals_kind = col_character(), meal_id = col_double(), readings_kind = col_character() )) %&gt;% mutate( user_id = as.character(user_id), time = as.timestamp(time), meals_kind = as.meals_kind(meals_kind), readings_kind = fct_relevel(readings_kind, c(&quot;premeal&quot;, &quot;postmeal&quot;)) ) head(bg_readings) ## user_id time bg meals_kind meal_id readings_kind ## 1 24 2019-01-02 21:10:00 81 dinner 811 premeal ## 2 24 2019-01-02 22:45:00 94 dinner 811 postmeal ## 3 24 2019-01-03 06:15:00 84 morning_snack 812 premeal ## 4 24 2019-01-03 07:20:00 89 morning_snack 812 postmeal ## 5 24 2019-01-03 07:25:00 89 breakfast 813 premeal ## 6 24 2019-01-03 09:05:00 85 breakfast 813 postmeal meals_data = read_mealyzer_files(raw_data_path, users[[&quot;user_id&quot;]], &quot;mealyzer_data.csv&quot;, add_user_id = FALSE, col_types = cols()) %&gt;% mutate( user_id = as.character(user_id), eaten_at = as.timestamp(eaten_at), kind = as.meals_kind(kind), premeal_bg_time = as.timestamp(premeal_bg_time), postmeal_bg_time = as.timestamp(postmeal_bg_time), premeal_bg_delay_minutes = as.double(difftime(eaten_at, premeal_bg_time, units = &quot;mins&quot;)), postmeal_bg_delay_minutes = as.double(difftime(postmeal_bg_time, eaten_at, units = &quot;mins&quot;)), bg_impact = postmeal_bg - premeal_bg, bg_impact_slope = bg_impact / (premeal_bg_delay_minutes + postmeal_bg_delay_minutes) ) head(meals_data) ## # A tibble: 6 x 35 ## user_id meal_id eaten_at title ingredients kind ## &lt;chr&gt; &lt;dbl&gt; &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; ## 1 24 811 2019-01-02 22:11:26 Taco… Fried shri… dinn… ## 2 24 812 2019-01-03 06:20:17 Latte Espresso, … morn… ## 3 24 813 2019-01-03 07:35:04 0% f… 6oz fage y… brea… ## 4 24 814 2019-01-03 13:49:18 Appl… Granny Smi… lunch ## 5 24 819 2019-01-03 19:59:10 Steak Steak toma… dinn… ## 6 24 821 2019-01-04 06:48:27 Espr… 4oz 1% mil… morn… ## # … with 29 more variables: photo_file_name &lt;chr&gt;, carbs_eval &lt;dbl&gt;, ## # protein_eval &lt;dbl&gt;, fat_eval &lt;dbl&gt;, calories_eval &lt;dbl&gt;, ## # fiber_eval &lt;dbl&gt;, evaluator_id &lt;dbl&gt;, platemate_id &lt;lgl&gt;, ## # carbs_user &lt;dbl&gt;, protein_user &lt;dbl&gt;, fat_user &lt;dbl&gt;, ## # calories_user &lt;dbl&gt;, fiber_user &lt;dbl&gt;, premeal_bg &lt;dbl&gt;, ## # premeal_bg_time &lt;dttm&gt;, postmeal_bg &lt;dbl&gt;, postmeal_bg_time &lt;dttm&gt;, ## # eval_calories_computed &lt;dbl&gt;, eval_proportion_carbs &lt;dbl&gt;, ## # eval_proportion_protein &lt;dbl&gt;, eval_proportion_fat &lt;dbl&gt;, ## # user_calories_computed &lt;dbl&gt;, user_proportion_carbs &lt;dbl&gt;, ## # user_proportion_protein &lt;dbl&gt;, user_proportion_fat &lt;dbl&gt;, ## # premeal_bg_delay_minutes &lt;dbl&gt;, postmeal_bg_delay_minutes &lt;dbl&gt;, ## # bg_impact &lt;dbl&gt;, bg_impact_slope &lt;dbl&gt; "],
["data-transformation.html", "Chapter 3 Data transformation 3.1 Anonymized timestamps 3.2 Other calculations", " Chapter 3 Data transformation 3.1 Anonymized timestamps All data coming out of this study was anonymized. As a part of anonymization the actual timestamps were replaced with a number of seconds since user’s anchor timestamp, which is defined as the time when they took the first recording with the app. Part of the data transformation was to convert timestamps from a number of seconds format to an actual timestams (POSIXct) fromat, assumig the same anchor date for all users (2019-01-01 00:00:00 EST). The by-product of this transformation was that it aligned all timeseries data to the same starting point, making it easy to compare across users. 3.2 Other calculations Assitional calculated fields were introduced: user_id converted from numeric to character type eaten_at converted to normalized timestamp kind converted to a factor premeal_bg_time converted to normalized timestamp postmeal_bg_timeconverted to normalized timestamp premeal_bg_delay_minutes calculated number of minutes before premeal BG is taken and the meal postmeal_bg_delay_minutes calculated number of minutes after the meal when postmeal BG was taken bg_impact calculated difference between postmeal_bg and premeal_bg bg_impact_slope ratio of bg_impact over the duration in minutes between post-meal and pre-meal times. Higher bg_impact_slope means faster BG increase abter the meal "],
["missing-values.html", "Chapter 4 Missing values", " Chapter 4 Missing values extracat::visna(meals_data) THere were different versions of the app. Some versions of the app asked users to enter nutritional estimation, but some version only asked on the goals, but not nutritional. meals_data %&gt;% ggplot() + geom_boxplot(aes(x = user_id, y = premeal_bg_delay_minutes), varwidth = TRUE) + scale_y_continuous(breaks=c(0, 15, 30, 45, 60), labels = c(&quot;0&quot;, &quot;15min&quot;, &quot;30min&quot;, &quot;45min&quot;, &quot;1h&quot;), limits = c(0, 60)) + coord_flip() + labs( title = &quot;&quot; ) ## Warning: Removed 125 rows containing non-finite values (stat_boxplot). Talking point: at some version the users were prevented from entering post meal before they are entered premeal, and users were forced to re-enter (backfill) previous meal BG. This led to a lot og outlyers. meals_data %&gt;% ggplot() + geom_boxplot(aes(x = user_id, y = postmeal_bg_delay_minutes), varwidth = TRUE) + scale_y_continuous(breaks=c(0, 60, 120, 180, 240), labels = c(&quot;0&quot;, &quot;1h&quot;, &quot;2h&quot;, &quot;3h&quot;, &quot;4h&quot;), limits = c(0, 1000)) + coord_flip() + labs( title = &quot;&quot; ) ## Warning: Removed 863 rows containing non-finite values (stat_boxplot). TODO: explain how the data was backfilled, not every user captured post BG in the app, even after reminders. However later on the association between the meal and pre and post BG were re-calculated based on the timestamps and pre/post BG were picked as timestamps around the meal. "],
["results.html", "Chapter 5 Results 5.1 Consistent meal times vs grazers 5.2 Meal kind analysis 5.3 Per user analysis", " Chapter 5 Results 5.1 Consistent meal times vs grazers meals_data %&gt;% mutate(eaten_at_hour = hour(eaten_at)) %&gt;% ggplot() + geom_histogram(aes(x=eaten_at_hour), bins = 24) + facet_wrap(~user_id, ncol = 7) + labs( title = &quot;Distribution of hours when users had a meal&quot; ) + theme( #strip.text = element_text(size=25) ) Talking point: eating patterns of people - two humps, three humps, no pattern. If eating twice a day, what meal ater they skipping? 5.2 Meal kind analysis dplyr::summarise(group_by(meals_data, user_id, kind), freq = n()) %&gt;% group_by(user_id) %&gt;% mutate(prop = freq/sum(freq)) %&gt;% ungroup() %&gt;% ggplot(aes(x = user_id, y = prop, fill = forcats::fct_rev(kind))) + geom_bar(stat = &quot;identity&quot;) + coord_flip() + labs(x = &quot;User ID&quot;, y = &quot;Proportion&quot;, title = &quot;Proportion of All Meals by Meal Kind&quot;) + theme(legend.title = element_blank(), legend.position=&quot;bottom&quot;) + guides(fill = guide_legend(nrow = 1, reverse=T)) Talking point: lots of people eat breakfast, lot o people capture snacks (good study subjects) meals_data %&gt;% select(user_id,carbs_eval, protein_eval,fat_eval,fiber_eval) %&gt;% gather(key = &quot;variable&quot;, value, -user_id) %&gt;% group_by(user_id, variable) %&gt;% summarise(total=sum(value, na.rm = T)) %&gt;% group_by(user_id) %&gt;% mutate(prop = total/sum(total)) %&gt;% ungroup() %&gt;% ggplot(aes(x = user_id, y = prop, fill = forcats::fct_rev(variable))) + geom_bar(stat = &quot;identity&quot;) + coord_flip() + labs(x = &quot;User ID&quot;, y = &quot;Proportion&quot;, title = &quot;Proportion of All Meals by Nutrient&quot;) + theme(legend.title = element_blank(), legend.position=&quot;bottom&quot;) + guides(fill = guide_legend(nrow = 1, reverse=T)) Question: need a better visulization. Protein and carbs are easy to compare across (they are aligned at the ends), but fat and fiber are difficult to compare across users. 5.3 Per user analysis 5.3.1 Correlation between variables focus_user_id = &quot;2475&quot; library(lattice) #sploms meals_data %&gt;% filter(user_id == focus_user_id) %&gt;% mutate( protein_fat=eval_proportion_protein-eval_proportion_fat, protein_carb=eval_proportion_protein-eval_proportion_carbs, carb_fat=eval_proportion_carbs-eval_proportion_fat) %&gt;% select(calories_eval, carbs_eval, fat_eval, protein_eval, fiber_eval, premeal_bg, postmeal_bg, bg_impact, protein_fat, protein_carb, carb_fat) %&gt;% splom() library(lattice) #sploms meals_data %&gt;% filter(user_id == focus_user_id) %&gt;% mutate( protein_fat_log_ratio=log(eval_proportion_protein/(eval_proportion_fat+0.0000001)), protein_carb_log_ratio=log(eval_proportion_protein/(eval_proportion_carbs+0.0000001)), carb_fat_log_ratio=log(eval_proportion_carbs/(eval_proportion_fat+0.0000001)) ) %&gt;% select(eval_calories_computed, eval_proportion_carbs, eval_proportion_fat, eval_proportion_protein, premeal_bg, postmeal_bg, bg_impact, protein_fat_log_ratio, protein_carb_log_ratio, carb_fat_log_ratio) %&gt;% splom() Talking points: Correlation between calories_eval and all carbs|fat|protein, but much smaller correlation to fiber. Fiber is counted as carbs when calculating the calories_calculated. So when evaluators were estimating the calories_eval, they should have been discurding fiber. premeal_bg and postmeal_bg - positively correlated negative correlation between eval_proportion_carbs &amp; eval_proportion_fat interactions between …_log_ratio varables split the meals into 2 or 3 clusters 5.3.2 Time effect 5.3.3 Meal BG impact visualization meals_data %&gt;% #filter(user_id == focus_user_id) %&gt;% ggplot() + facet_wrap(~user_id, ncol = 7) + geom_segment(aes(x = -premeal_bg_delay_minutes, xend = postmeal_bg_delay_minutes, y=premeal_bg, yend=postmeal_bg), alpha = 0.5) + scale_x_continuous(breaks=c(-15, 0, 60, 120, 180, 240), labels = c(&quot;-15min&quot;, &quot;0&quot;, &quot;1h&quot;, &quot;2h&quot;, &quot;3h&quot;, &quot;4h&quot;), limits = c(-15, 180)) + theme( strip.text = element_text(size=25) ) ## Warning: Removed 1678 rows containing missing values (geom_segment). Talking point: some users take insulin. Need to have a data back it up. Lots of users that have a flat response, and some users have big ups and downs. "],
["images.html", "Chapter 6 Images 6.1 Meal nutrients evaluator vs user 6.2 Overtime trends 6.3 Sleep", " Chapter 6 Images display_meals &lt;- function(df, ncol = 6, nrow = 3, rotate = 0) { meals = df[1:(ncol*nrow), ] %&gt;% select(user_id, meal_id) filenames = paste0(normalizePath(&quot;~/Dropbox/MealyzerData&quot;), &quot;/&quot;, meals[[&quot;user_id&quot;]], &quot;/images/medium/&quot;, meals[[&quot;meal_id&quot;]], &quot;.jpg&quot;) #print(filenames) data_uris = sapply(filenames, knitr::image_uri) images = tibble(src = data_uris) r2d3(data=images, script = &quot;display_meals.js&quot;, container = &quot;div&quot;, options=list(ncol=ncol, nrow=nrow, rotate=rotate)) } meals_data %&gt;% filter(user_id == focus_user_id) %&gt;% arrange(desc(calories_eval)) %&gt;% #print_df(bg_impact, title, ingredients, calories_eval) %&gt;% display_meals(ncol = 6, nrow = 3, rotate = 0) meals_data %&gt;% filter(user_id == focus_user_id) %&gt;% arrange(calories_eval) %&gt;% #print_df(bg_impact, title, ingredients, calories_eval) %&gt;% display_meals(ncol = 6, nrow = 3, rotate = 0) Talking point: * there are a few testing images users made, and they will need to be found and ignored for future analysis. 6.1 Meal nutrients evaluator vs user meals_data %&gt;% mutate( calories_diff = calories_user - calories_eval, carbs_diff = carbs_user - carbs_eval, protein_diff = protein_user - protein_eval, fat_diff = fat_user - fat_eval, fiber_diff = fiber_user - fiber_eval ) %&gt;% filter(!is.na(calories_diff)) %&gt;% ggplot() + geom_histogram(aes(x = carbs_diff), bins = 30)+ facet_wrap(~user_id, ncol = 4) Talking points: Aggregate distribution is simmetrical around 0. there is no bias on either side. At averages out per user. THis is BIG! no need to do evaluator estimates if usrs are good at that. meals_data %&gt;% mutate( calories_diff = calories_user - calories_eval, carbs_diff = carbs_user - carbs_eval, protein_diff = protein_user - protein_eval, fat_diff = fat_user - fat_eval, fiber_diff = fiber_user - fiber_eval ) %&gt;% filter(!is.na(calories_diff) &amp; !is.na(carbs_diff) &amp; !is.na(protein_diff) &amp; !is.na(fat_diff) &amp; !is.na(fiber_diff)) %&gt;% gather(key = &quot;type&quot;, value = &quot;diff&quot;, carbs_diff, protein_diff, fat_diff, fiber_diff) %&gt;% ggplot() + #facet_wrap(~user_id, ncol = 6, scales = &quot;free_x&quot;) + geom_boxplot(aes(x = reorder(type, diff, median), y = diff)) + coord_flip() Talking point: Slight under-counting of the calories, but not as much as I would expect. High density at 0, suggesting lots of meal the evaluator and user entered exactly the same number of calories, possibly because of 0 calory meal (e.g. water) or known calory meal (e.g. protein bar) Systematic under-counting of carbs, slight over-counting of fiber 6.2 Overtime trends Have the ability of users to estimate nutrients change overtime with the use of the app? Question TODO: have users started to eat less in general or changed the nutritional make up of their meals? Look at nutrient proportions trends, look at grams in meals across all nutrients. IF people are reducing calories, are they redicing the size of meals or change proportions? meals_data %&gt;% mutate(eaten_at_date = as.Date(eaten_at, tz = &quot;EST&quot;)) %&gt;% filter(eaten_at_date &lt;&quot;2019-04-01&quot;) %&gt;% group_by(user_id, eaten_at_date) %&gt;% summarise(sum_by_day = sum(calories_eval)) %&gt;% ggplot(aes(x=eaten_at_date, y=sum_by_day))+ geom_point(size=0.3)+ geom_smooth(method = &quot;lm&quot;)+ facet_wrap(~user_id, ncol=7) + labs ( title = &quot;Calories trends by user&quot; ) ## Warning: Removed 288 rows containing non-finite values (stat_smooth). ## Warning: Removed 288 rows containing missing values (geom_point). # TODO: colorcode facets whis positive vs negative trend meals_data %&gt;% mutate(eaten_at_date = as.Date(eaten_at, tz = &quot;EST&quot;)) %&gt;% filter(eaten_at_date &lt;&quot;2019-04-01&quot;) %&gt;% group_by(user_id, eaten_at_date) %&gt;% summarise(sum_by_day = sum(carbs_eval)) %&gt;% ggplot(aes(x=eaten_at_date, y=sum_by_day))+ geom_point(size=0.3)+ geom_smooth(method = &quot;lm&quot;)+ facet_wrap(~user_id, ncol=7) + labs ( title = &quot;Carbs trends by user&quot; ) ## Warning: Removed 288 rows containing non-finite values (stat_smooth). ## Warning: Removed 288 rows containing missing values (geom_point). bg_readings %&gt;% filter(time &lt;&quot;2019-05-01 00:00:00&quot;) %&gt;% ggplot(aes(x = time, y = bg)) + geom_line() + facet_wrap(~user_id,ncol=7) + theme(axis.text=element_text(size=5, angle = 90)) TODO: Plotting pre and post causes a lot of jagginess. Either plot trend of pre BG or a trend of post BG, or a two parallel trendlines. Also look at “fasting” bg overtime. Our data is a proxy for the true “fasting” BG in the morning. It hsould be below 110. bg_readings %&gt;% #mutate(time = round_date(time, &#39;1 hours&#39;)) %&gt;% mutate(time = format(as.POSIXct(time,format=&quot;%H:%M:%S&quot;),&quot;%H&quot;)) %&gt;% group_by(user_id, time) %&gt;% summarise(avg_bg = mean(bg)) %&gt;% ggplot(aes(x=time, y=avg_bg))+ geom_point(size=0.3)+ facet_wrap(~user_id, ncol=7) + labs(x=&quot;Hour&quot;, y=&quot;Average BG Level&quot;)+ ggtitle(&quot;Average BG Level by Hour&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) + theme(axis.text=element_text(size=5, angle = 90)) 6.3 Sleep sleep = read_csv(file.path(raw_data_path, &quot;1983&quot;, &quot;sleep.csv&quot;), col_types = cols()) %&gt;% mutate(time = as.timestamp(time)) Questions: * does the amount of sleep impact the first BG reading in the day (pre-breakfast, important!) (the very first pre-breakfst BG reading is considered fasting and is a true-ish representation of glycemic control (how bad is your diabetis)). * Does amount (or quality of sleep) have an impoact on pre-breakfast BG (&lt;- new measure). * Urban mith - the quality/amount of sleep may change how people respond to meals, e.g. for the same nutritional breakdown of a meal BG_impoact will be different. Fat and protein mediate the impact of carbohidrate. How to show this (focus on the visualization, data may be lacking the signal) "],
["interactive-component.html", "Chapter 7 Interactive component", " Chapter 7 Interactive component "],
["conclusion.html", "Chapter 8 Conclusion", " Chapter 8 Conclusion "],
["experiments-visualizing-data.html", "Chapter 9 Experiments visualizing data", " Chapter 9 Experiments visualizing data Qualify dataset (missing data) Interesting questions Interactive viz (Something like Tableau) select variables, selecting filters, selecting smoothers 9.0.1 Dataset highlevel view premeal_delay_buckets = c(&quot;&lt; 15 min&quot;, &quot;10 - 60 min&quot;, &quot;&gt; 60 min&quot;) meals_data %&gt;% #filter(user_id == 2392) %&gt;% #filter(premeal_bg_delay_minutes &lt;= 300 &amp; premeal_bg_delay_minutes &gt;= 0) %&gt;% #mutate(premeal_bg_delay = ifelse(premeal_bg_delay_minutes &lt; 15, premeal_delay_buckets[1], ifelse(premeal_bg_delay_minutes &lt; 60, premeal_delay_buckets[2], premeal_delay_buckets[3]))) %&gt;% #mutate(premeal_bg_delay = fct_relevel(premeal_bg_delay, premeal_delay_buckets)) %&gt;% #print_df(user_id, premeal_bg_time, eaten_at, premeal_bg_delay_minutes) %&gt;% ggplot() + #geom_bar(aes(x=premeal_bg_delay, fill=premeal_bg_delay)) + geom_histogram(aes(x=premeal_bg_delay_minutes), binwidth = 30) + scale_x_continuous(breaks=c(0, 60, 120, 180, 240, 300), labels = c(&quot;0&quot;, &quot;1h&quot;, &quot;2h&quot;, &quot;3h&quot;, &quot;4h&quot;, &quot;5h&quot;), limits = c(0, 300)) + facet_wrap(~user_id, ncol = 7, scales = &quot;free_y&quot;) + labs( title = &quot;Delay of premeal BG recordings, bucketed&quot; ) + theme( legend.position=&quot;top&quot;, #axis.title.x = element_blank(), #axis.text.x = element_blank(), #axis.ticks.x = element_blank() axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank(), strip.text = element_text(size=25), ) ## Warning: Removed 29 rows containing non-finite values (stat_bin). ## Warning: Removed 56 rows containing missing values (geom_bar). postmeal_delay_buckets = c(&quot;&lt; 1 hour&quot;, &quot;1 - 2 hours&quot;, &quot;&gt; 2 hours&quot;) meals_data %&gt;% #mutate(postmeal_bg_delay = ifelse(postmeal_bg_delay_minutes &lt; 60, postmeal_delay_buckets[1], ifelse(postmeal_bg_delay_minutes &lt; 120, postmeal_delay_buckets[2], postmeal_delay_buckets[3]))) %&gt;% #mutate(postmeal_bg_delay = fct_relevel(postmeal_bg_delay, postmeal_delay_buckets)) %&gt;% #print_df(user_id, eaten_at, postmeal_bg_time, postmeal_bg_delay_minutes) %&gt;% ggplot() + #geom_bar(aes(x=postmeal_bg_delay, fill=postmeal_bg_delay)) + geom_histogram(aes(x=postmeal_bg_delay_minutes), binwidth = 30) + #geom_density(aes(x = postmeal_bg_delay_minutes)) + facet_wrap(~user_id, ncol = 7) + scale_x_continuous(breaks=c(0, 60, 120, 180, 240, 300), labels = c(&quot;0&quot;, &quot;1h&quot;, &quot;2h&quot;, &quot;3h&quot;, &quot;4h&quot;, &quot;5h&quot;), limits = c(0, 300)) + labs( title = &quot;Delay of postmeal BG recordings, bucketed&quot; ) + theme( legend.position=&quot;top&quot;, axis.title.x = element_blank(), #axis.text.x = element_blank(), #axis.ticks.x = element_blank() #axis.title.y = element_blank(), #axis.text.y = element_blank(), #axis.ticks.y = element_blank() strip.text = element_text(size=25), ) ## Warning: Removed 959 rows containing non-finite values (stat_bin). ## Warning: Removed 56 rows containing missing values (geom_bar). 9.0.2 Plotting activeness vs. bg level bg_readings %&gt;% group_by(meal_id) %&gt;% mutate(change_in_bg = c(0,diff(bg)/first(bg))) %&gt;% select(user_id, change_in_bg) %&gt;% filter(change_in_bg != 0) %&gt;% group_by(user_id) %&gt;% summarise(n = n(), avg_change_in_bg = mean(change_in_bg)) %&gt;% mutate(activeness = ifelse(n &gt; median(n), &quot;high&quot;,&quot;low&quot;)) %&gt;% ggplot(aes(x=seq_along(avg_change_in_bg), y=avg_change_in_bg)) + geom_point(aes(colour=activeness)) ## Adding missing grouping variables: `meal_id` 9.0.3 Plotting pre/post meal bg ,faceting on user_id bg_readings %&gt;% group_by(meal_id) %&gt;% mutate(premeal = first(bg), postmeal =last(bg)) %&gt;% select(user_id, meals_kind, premeal, postmeal) %&gt;% distinct() %&gt;% ggplot(aes(x=premeal, y=postmeal)) + geom_point(size = 0.2, aes(colour=meals_kind)) + facet_wrap(~user_id, ncol = 7) ## Adding missing grouping variables: `meal_id` parcoords( meals_data %&gt;% select(kind,carbs_eval, protein_eval,fat_eval,fiber_eval,calories_eval, bg_impact) , rownames = F # turn off rownames from the data.frame , brushMode = &quot;1D-axes&quot; , reorderable = T , queue = T, alpha = 0.05, color = list( colorBy = &quot;kind&quot; , colorScale = &quot;scaleOrdinal&quot; , colorScheme = &quot;schemeCategory10&quot; ) , withD3 = TRUE ) TODO: look are nutritional profile of each person - distribution of nutrients per meal, e.g. for person X, an aerage breakfast has this distribution of carbs/fat/protein/fiber, and dinner looks like this…. parcoords( meals_data %&gt;% select(user_id, kind, bg_impact, calories_eval, carbs_eval, protein_eval,fat_eval,fiber_eval) %&gt;% gather(key = &quot;variable&quot;, value, -user_id,-kind) %&gt;% group_by(user_id, kind, variable) %&gt;% summarise(avg_eval=mean(value, na.rm = T)) %&gt;% spread(variable, avg_eval) , rownames = F # turn off rownames from the data.frame , brushMode = &quot;1D-axes&quot; , reorderable = T , queue = T, alpha = 0.3, color = list( colorBy = &quot;kind&quot; , colorScale = &quot;scaleOrdinal&quot; , colorScheme = &quot;schemeCategory10&quot; ) , withD3 = TRUE ) TODO: THe ultimate question: for a person, what is the cause of the glicemic impact? Can we show how to attribute the change of bg_impact to a sibgle nutrient or a combination. meals_data %&gt;% select(user_id, kind,carbs_eval, protein_eval,fat_eval,fiber_eval,calories_eval, bg_impact) %&gt;% mutate_if(is.numeric, scale) %&gt;% mutate(ID = 1:3303) %&gt;% gather(key = &quot;variable&quot;, value, -user_id,-kind, -ID) %&gt;% ggplot(aes(x=variable,y=value,colour=kind, group=ID))+ geom_line(alpha=0.5)+facet_wrap(~user_id,ncol=7)+ theme( legend.position=&quot;top&quot;, axis.text=element_text(size=5, angle = 90) ) ## Warning: attributes are not identical across measure variables; ## they will be dropped ## Warning: Removed 3812 rows containing missing values (geom_path). meals_data %&gt;% select(user_id, kind,carbs_eval, protein_eval,fat_eval,fiber_eval, bg_impact) %&gt;% #mutate(ID = 1:3303) %&gt;% gather(key = &quot;variable&quot;, value, -user_id,-kind) %&gt;% group_by(user_id, kind, variable) %&gt;% summarise(avg_eval=mean(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate_if(is.numeric, scale) %&gt;% #gather(key = &quot;variable&quot;, value, -user_id,-kind, -ID, -avg_eval) %&gt;% ggplot(aes(x=variable,y=avg_eval,group=1))+ geom_line(alpha=0.5)+ coord_flip() + facet_wrap(~user_id,ncol=7) sleep %&gt;% ggplot() + geom_point(aes(x=time, y= seconds,color=factor(level)), size=0.5) sleep %&gt;% filter(level %in% c(&quot;deep&quot;,&quot;light&quot;,&quot;rem&quot;,&quot;wake&quot;)) %&gt;% ggplot(aes(x = seconds)) + geom_histogram(alpha=.7, color=&quot;black&quot;, fill=&quot;steelblue2&quot;, bins = 32) + facet_wrap( ~level) + xlab(&quot;Time Frame in Seconds&quot;) + ylab(&quot;Count&quot;) + ggtitle(&quot;Histogram of Time Frames By Sleep Stage&quot;) + theme(plot.title = element_text(face = &quot;bold&quot;)) library(&quot;ggridges&quot;) ## ## Attaching package: &#39;ggridges&#39; ## The following object is masked from &#39;package:ggplot2&#39;: ## ## scale_discrete_manual sleep %&gt;% filter(level %in% c(&quot;deep&quot;,&quot;light&quot;,&quot;rem&quot;,&quot;wake&quot;)) %&gt;% ggplot(aes(x = seconds, y = level, fill = level)) + geom_density_ridges_gradient(scale = 2) + theme_ridges()+ scale_y_discrete(expand = c(0.3, 0)) + scale_x_continuous(expand = c(0.01, 0))+ labs(x=&quot;Time Frames&quot;, y=&quot;Sleep Stage&quot;)+ ggtitle(&quot;Density Curves of Time Frames by Sleep Stage&quot;)+ theme(plot.title = element_text(hjust = 0.6)) + guides(fill = guide_legend(reverse=T)) ## Picking joint bandwidth of 164 distance = read.csv(&quot;~/Dropbox/MealyzerData/1983/activities-distance_overview.csv&quot;, header=T) calories = read.csv(&quot;~/Dropbox/MealyzerData/1983/activities-calories_overview.csv&quot;, header=T) steps = read.csv(&quot;~/Dropbox/MealyzerData/1983/activities-steps_overview.csv&quot;, header=T) activities &lt;- merge(steps, merge(distance, calories, by = &quot;date&quot;, all = TRUE), by = &quot;date&quot;, all = TRUE) colnames(activities) &lt;- c(&quot;date&quot;,&quot;steps&quot;,&quot;distance&quot;,&quot;calories&quot;) # date vs. calories,distance,steps for user #1983 activities %&gt;% mutate(date = date(as.timestamp(date))) %&gt;% slice(1:133) %&gt;% # weird data after this point gather(key = key, value = value, -date) %&gt;% ggplot(aes(date, value, col=key)) + geom_line() # scale the above data activities %&gt;% mutate(date = date(as.timestamp(date))) %&gt;% slice(1:133) %&gt;% # weird data after this point gather(key = key, value = value, -date) %&gt;% group_by(key) %&gt;% mutate(index = round(100*value/value[1], 2)) %&gt;% ungroup() %&gt;% ggplot(aes(date, index, col=key)) + geom_line() # once scaled, we see that the data for distance and steps completely overlaps, suggesting that one is a linear function of another. user1983 = bg_readings %&gt;% mutate(date=date(time)) %&gt;% group_by(user_id, date) %&gt;% mutate(avg_bg=mean(bg)) %&gt;% select(user_id,date,avg_bg) %&gt;% unique() %&gt;% filter(user_id==1983) %&gt;% slice(1:72) # weird data after this point user1983 %&gt;% ggplot(aes(date, avg_bg)) + geom_line() # plot avg_bg vs. calories for user #1983 activities %&gt;% mutate(date = date(as.timestamp(date))) %&gt;% full_join(user1983, by=&quot;date&quot;) %&gt;% #or use merge? select(-user_id, -distance, -steps) %&gt;% filter(date &lt; &quot;2019-04-01&quot;) %&gt;% gather(key = key, value = value, -date) %&gt;% group_by(key) %&gt;% mutate(index = round(100*value/value[1], 2)) %&gt;% ungroup() %&gt;% ggplot(aes(date, index, col=key)) + geom_line() ## Warning: Removed 2 rows containing missing values (geom_path). # We see that there are missing values for average BG, which is normal since bg level and calories burnt are measured by two different devices/apps. # Based on the data we have here, we see that avg_bg has a nagative relationship with calories burnt, where higher avg_bg usually is associated with lower calories burnt that day. #user 1983&#39;s avg_bg vs. minutesasleep by day sleep_overview = read.csv(&quot;~/Dropbox/MealyzerData/1983/sleep_overview.csv&quot;) sleep_overview %&gt;% mutate(date=date(as.timestamp(dateOfSleep))) %&gt;% arrange(date) %&gt;% # to perform correct scaling, must have date in ascending order group_by(date) %&gt;% mutate(minutesAsleep = sum(minutesAsleep)) %&gt;% full_join(user1983, by=&quot;date&quot;) %&gt;% #merge? select(date, minutesAsleep, avg_bg) %&gt;% filter(date &lt; &quot;2019-04-01&quot;) %&gt;% gather(key = key, value = value, -date) %&gt;% group_by(key) %&gt;% mutate(index = round(100*value/value[1], 2)) %&gt;% ungroup() %&gt;% ggplot(aes(date, index, col=key)) + geom_line() ## Warning: Removed 3 rows containing missing values (geom_path). # user 1983&#39;s parcoords parcoords( sleep_overview %&gt;% select(-minutesToFallAsleep) %&gt;% mutate(date=date(as.timestamp(dateOfSleep))) %&gt;% group_by(date) %&gt;% mutate(minutesAsleep = sum(minutesAsleep)) %&gt;% merge(user1983, by=&quot;date&quot;) %&gt;% ungroup() %&gt;% select(-minutesAfterWakeup, -date, - user_id) , rownames = F # turn off rownames from the data.frame , brushMode = &quot;1D-axes&quot; , reorderable = T , queue = T, alpha = 0.5, color = list( colorBy = &quot;kind&quot; , colorScale = &quot;scaleOrdinal&quot; , colorScheme = &quot;schemeCategory10&quot; ) , withD3 = TRUE ) # arrange in this order: # dateOfSleep, endTime, startTime, minutesAwake, minutesAsleep, efficiency, ang_bg, duration, timeInBed # Looks like dateOfSleep, endTime, startTime are the same, so is duration, timeInBed # avg_bg is correlated with the duration - which may be a good talking point "]
]
